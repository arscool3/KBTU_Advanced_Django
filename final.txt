Endterm + Final + meta info

на 14 неделе (27.04) будет последняя лекция на вебсокеты, их не будет в требованиях на файнал, но думаю будет интересно послушать про них )

на endterm и final будет один проект
дедлайн - 15 неделя, защита файнала, если на 15 неделе плохо сдали и есть комментарии от меня, вы можете пересдать на 16 неделе без штрафных баллов

вы должны использовать Fastapi

По требованиям, самое главное это понимать дизайн, для чего вы используете тот или иной подход. Почему fastapi , почему kafka, почему redis ? Все эти вопросы я буду задавать во время защиты проекта

Вот минимальные требования

FastApi 
1) 6 models
2) 4 Relationships
AUTHORIZATION
4) Background Tasks (Dramatiq / Celery)
5) Postgres DB
6) 3 DI (2 func, 1 class)
7) Kafka
8) views

celery helps process vast amounts of msgs
while providing operations with tools required
to maintain such a System
it is a task queue that focuses on real-time processing
and supports task scheduling
*allows to run tasks from ur python app asynchronously
cellery will run  it while in ur app u can continue to do whatever u want


Again, to improve user experience, long-running processes should be run outside the normal HTTP request/response flow, in a background process.

Examples:

Running machine learning models
Sending confirmation emails
Web scraping and crawling
Analyzing data
Processing images
Generating reports



Since we'll need to manage three processes in total (FastAPI, Redis, Celery worker), we'll use Docker to simplify our workflow by wiring them up so that they can all be run from one terminal window with a single command.


aiofiles==23.1.0
celery==5.2.7
fastapi==0.95.0
Jinja2==3.1.2
pytest==7.2.2
redis==4.5.4
requests==2.28.2
uvicorn==0.21.1
httpx==0.23.3


Celery uses a message broker -- RabbitMQ, Redis, or AWS Simple Queue Service (SQS) -- to facilitate communication between the Celery worker and the web application. Messages are added to the broker, which are then processed by the worker(s). Once done, the results are added to the backend.
Redis will be used as both the broker and backend. Add both Redis and a Celery worker to the docker-compose.yml file like so: